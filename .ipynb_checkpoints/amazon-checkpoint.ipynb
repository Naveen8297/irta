{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# remove NaN\n",
    "dataAfter = df.dropna(subset=[\"reviews.rating\"])\n",
    "\n",
    "# convert the rating to integer\n",
    "dataAfter[\"reviews.rating\"] = dataAfter[\"reviews.rating\"].astype(int)\n",
    "df = dataAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# implement sentiment analysis\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "def get_sentiment(text):\n",
    "    sent = analyser.polarity_scores(text)\n",
    "    max = np.max(sent)\n",
    "    if sent['neg'] > sent['neu'] and sent['neg'] > sent['pos']:\n",
    "        return \"NEGATIVE\"\n",
    "    if sent['neu'] > sent['pos'] and sent['neu'] > sent['neg']:\n",
    "        return \"NEUTRAL\"\n",
    "    if sent['pos'] > sent['neu'] and sent['pos'] > sent['neg']:\n",
    "        return \"POSITIVE\"\n",
    "    # return np.array([sent['neg'], sent['neu'], sent['pos']])\n",
    "\n",
    "\n",
    "df['reviews.sentiment'] = df['reviews.text'].apply(get_sentiment)\n",
    "df['reviews.sent_text'] = df['reviews.sentiment'] + \" \" + df['reviews.text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('review')\n",
    "stop_words.add('that')\n",
    "\n",
    "# to lowercase\n",
    "df['reviews.text'] = df['reviews.text'].str.lower()\n",
    "\n",
    "# Lemmatization\n",
    "df['reviews.text'] = df['reviews.text'].apply(lemmatize_text)\n",
    "\n",
    "# Remove stop words\n",
    "df['reviews.text'] = df['reviews.text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# Rejoing the words into a sentence\n",
    "df['reviews.text'] = df['reviews.text'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# print(df['reviews.sent_text'])\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(df['reviews.text'])\n",
    "X = cv.transform(df['reviews.text'])\n",
    "# X = list(df['reviews.sentiment'])\n",
    "y = df['reviews.rating']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 115    1    3    3   75]\n",
      " [  14   47    2    8   55]\n",
      " [   2    8  133    9   92]\n",
      " [   1    0    3  691  433]\n",
      " [   8    1    4   59 3900]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.58      0.68       197\n",
      "           2       0.82      0.37      0.51       126\n",
      "           3       0.92      0.55      0.68       244\n",
      "           4       0.90      0.61      0.73      1128\n",
      "           5       0.86      0.98      0.91      3972\n",
      "\n",
      "    accuracy                           0.86      5667\n",
      "   macro avg       0.86      0.62      0.70      5667\n",
      "weighted avg       0.87      0.86      0.85      5667\n",
      "\n",
      "0.8621845773778013\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6950444726810674\n",
      "Accuracy for C=0.05: 0.6915148948185798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.6817732599181138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "temp = df.sample(len(df))\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(df['reviews.text'])\n",
    "X = cv.transform(df['reviews.text'])\n",
    "X_test = cv.transform(df['reviews.text'])\n",
    "\n",
    "target = temp['reviews.rating']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%    \n"
    }
   },
   "outputs": [],
   "source": [
    "final_model = LogisticRegression(C=0.01)\n",
    "final_model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_model.predict(X_test)))\n",
    "\n",
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df[\"reviews.rating\"].value_counts()/len(df)   #percentage of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "reviews = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "reviews.groupby(\"asins\")[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,10))\n",
    "ax1 = plt.subplot(211)\n",
    "#ax2 = plt.subplot(212, sharex = ax1)\n",
    "reviews[\"asins\"].value_counts().plot(kind=\"bar\", ax=ax1, title=\"ASIN Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix = reviews.corr()\n",
    "corr_matrix\n",
    "# Here we can analyze reviews.ratings with asins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "counts = reviews[\"asins\"].value_counts().to_frame()\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "avg_rating = reviews.groupby(\"asins\")[\"reviews.rating\"].mean().to_frame()\n",
    "avg_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "table = counts.join(avg_rating)\n",
    "table.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(\"asins\", \"reviews.rating\", data=table)\n",
    "table.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
